import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import os
import joblib

# === Step 1: è¯»å–å¹¶æ¸…æ´—æ•°æ® ===
csv_path = r"F:\open_drifter\transform_drift\data\particles_output(no_wind).csv"
print("ğŸ“‚ æ­£åœ¨è¯»å– CSV æ–‡ä»¶...")
if not os.path.exists(csv_path):
    print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
    exit()

df = pd.read_csv(csv_path)
print("âœ… CSV æ–‡ä»¶è¯»å–æˆåŠŸï¼Œæ•°æ®è¡Œæ•°ï¼š", len(df))
print(df.head())

# åˆ é™¤é£åœºï¼Œåªä¿ç•™è½¨è¿¹ + æµåœº
features = ["lon", "lat", "x_sea_water_velocity", "y_sea_water_velocity"]
target = ["lon", "lat"]
seq_len = 10

# === Step 2: æ¸…æ´—æ•°æ® ===
df = df.replace([np.inf, -np.inf], np.nan).dropna()

for col in features + target:
    if df[col].nunique() <= 1:
        print(f"âš ï¸ åˆ— {col} ä¸ºå¸¸æ•°åˆ—ï¼Œå·²åˆ é™¤")
        df.drop(columns=[col], inplace=True)

# å†æ¬¡æ£€æŸ¥
if df.isnull().any().any():
    raise ValueError("âŒ æ•°æ®ä¸­å­˜åœ¨ NaNï¼Œè¯·æ£€æŸ¥ï¼")

# === Step 3: æ ‡å‡†åŒ– ===
print("ğŸ”„ æ­£åœ¨æ ‡å‡†åŒ–æ•°æ®...")
feature_scaler = StandardScaler()
target_scaler = StandardScaler()

df[features] = feature_scaler.fit_transform(df[features])
df[target] = target_scaler.fit_transform(df[target])

# === Step 4: æ„é€ åºåˆ—æ•°æ® ===
print("ğŸ§± æ­£åœ¨æ„é€ åºåˆ—æ ·æœ¬...")
X, Y = [], []
for i in range(len(df) - seq_len):
    X.append(df[features].iloc[i:i+seq_len].values)
    Y.append(df[target].iloc[i+seq_len].values)

X = np.array(X, dtype=np.float32)
Y = np.array(Y, dtype=np.float32)

if np.isnan(X).any() or np.isnan(Y).any():
    raise ValueError("âŒ æ„é€ åçš„æ•°æ®ä¸­å­˜åœ¨ NaNï¼")

print("âœ… æ„é€ å®Œæˆï¼ŒX shape:", X.shape, "Y shape:", Y.shape)

# æ•°æ®åˆ’åˆ†
X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

# === Step 5: æ„å»º Dataset å’Œ DataLoader ===
class DriftDataset(Dataset):
    def __init__(self, X, Y):
        self.X = torch.tensor(X)
        self.Y = torch.tensor(Y)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.Y[idx]

train_loader = DataLoader(DriftDataset(X_train, Y_train), batch_size=32, shuffle=True)
val_loader = DataLoader(DriftDataset(X_val, Y_val), batch_size=32)

print("âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œè®­ç»ƒæ ·æœ¬æ•°ï¼š", len(train_loader.dataset), "éªŒè¯æ ·æœ¬æ•°ï¼š", len(val_loader.dataset))

# === Step 6: æ¨¡å‹ç»“æ„ ===
class DriftTransformer(nn.Module):
    def __init__(self, input_dim=4, model_dim=128, nhead=8, num_layers=4, output_dim=2):
        super().__init__()
        self.input_proj = nn.Linear(input_dim, model_dim)
        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=nhead, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.output = nn.Linear(model_dim, output_dim)
   
    def forward(self, x):
        x = self.input_proj(x)
        x = self.transformer(x)
        x = x.mean(dim=1)
        return torch.tanh(self.output(x))  # é™åˆ¶è¾“å‡ºèŒƒå›´é˜²æ­¢çˆ†ç‚¸

# === Step 7: æ¨¡å‹è®­ç»ƒ ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DriftTransformer(input_dim=4).to(device)
print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œè®¾å¤‡ï¼š", device)
print(model)

criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
for epoch in range(1, 11):
    model.train()
    total_loss = 0
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        pred = model(xb)
        loss = criterion(pred, yb)

        # æ£€æŸ¥ NaN
        if torch.isnan(loss):
            print("âŒ NaN Loss æ£€æµ‹åˆ°ï¼")
            print("è¾“å…¥æ ·æœ¬:", xb)
            print("æ¨¡å‹è¾“å‡º:", pred)
            print("çœŸå®å€¼:", yb)
            exit()

        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    
    avg_loss = total_loss / len(train_loader)

    # éªŒè¯
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for xb, yb in val_loader:
            xb, yb = xb.to(device), yb.to(device)
            pred = model(xb)
            val_loss += criterion(pred, yb).item()
    
    avg_val_loss = val_loss / len(val_loader)
    print(f"âœ… Epoch {epoch:2d}: Train Loss = {avg_loss:.6f}, Val Loss = {avg_val_loss:.6f}")
    torch.save(model.state_dict(), "drift_transformer.pth")
    joblib.dump(feature_scaler, "feature_scaler.save")
    joblib.dump(target_scaler, "target_scaler.save")
